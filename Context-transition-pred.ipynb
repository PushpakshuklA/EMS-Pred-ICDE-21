{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOUdxHJQINbRAn0UL5tR/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PushpakshuklA/EMS-Pred-ICDE-21/blob/main/Context-transition-pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zcfinal/ContextTransitionPredictability"
      ],
      "metadata": {
        "id": "IVUJlitvPe9N",
        "outputId": "8e4bc191-10a1-4009-e24f-cb384aca3818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ContextTransitionPredictability' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import re\n",
        "#import entropy_time_bin\n",
        "\n",
        "def rand_entropy(sequence):\n",
        "    \"\"\"\n",
        "    Compute the \"random entropy\", that is, the entropy of a uniform distribution.\n",
        "    Equation:\n",
        "        S_{rand} = \\log_{2}(n), where n is the number of unique symbols in the input sequence.\n",
        "    Args:\n",
        "        sequence: 1-D array-like sequence of symbols.\n",
        "    Returns:\n",
        "        A float representing the random entropy of the input sequence.\n",
        "    Reference:\n",
        "        Limits of Predictability in Human Mobility. Chaoming Song, Zehui Qu,\n",
        "        Nicholas Blumm1, Albert-László Barabási. Vol. 327, Issue 5968, pp. 1018-1021.\n",
        "        DOI: 10.1126/science.1177170\n",
        "    \"\"\"\n",
        "    alphabet_size = len(np.unique(sequence))\n",
        "    return np.log2(alphabet_size)\n",
        "\n",
        "\n",
        "def unc_entropy(sequence):\n",
        "    \"\"\"\n",
        "    Compute temporal-uncorrelated entropy (Shannon entropy).\n",
        "    Equation:\n",
        "    S_{unc} = - \\sum p(i) \\log_2{p(i)}, for each symbol i in the input sequence.\n",
        "    Args:\n",
        "        sequence: the input sequence of symbols.\n",
        "    Returns:\n",
        "        temporal-uncorrelated entropy of the input sequence.\n",
        "    Reference:\n",
        "        Limits of Predictability in Human Mobility. Chaoming Song, Zehui Qu,\n",
        "        Nicholas Blumm1, Albert-László Barabási. Vol. 327, Issue 5968, pp. 1018-1021.\n",
        "        DOI: 10.1126/science.1177170\n",
        "    \"\"\"\n",
        "    _, counts = np.unique(sequence, return_counts=True)\n",
        "    probabilities = counts / counts.sum()\n",
        "    return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "\n",
        "def lambdas_naive(sequence):\n",
        "    \"\"\"\n",
        "    Compute the lambdas in the following equation:\n",
        "\n",
        "    Equation:\n",
        "        S_{real} = \\left( \\frac{1}{n} \\sum \\Lambda_{i} \\right)^{-1}\\log_{2}(n)\n",
        "\n",
        "    Args:\n",
        "        sequence: the input sequence of symbols.\n",
        "    Returns:\n",
        "        The sum of the average length of sub-sequences that\n",
        "        (up to a certain point) do not appear in the original sequence.\n",
        "    Reference:\n",
        "        Kontoyiannis, I., Algoet, P. H., Suhov, Y. M., & Wyner, A. J. (1998).\n",
        "        Nonparametric entropy estimation for stationary processes and random\n",
        "        fields, with applications to English text. IEEE Transactions on Information\n",
        "        Theory, 44(3), 1319-1327.\n",
        "    \"\"\"\n",
        "    lambdas = 0\n",
        "    for i in range(len(sequence)):\n",
        "        current_sequence = ','.join(sequence[0:i])\n",
        "        match = True\n",
        "        k = i\n",
        "        while match and k < len(sequence):\n",
        "            k += 1\n",
        "            match = ','.join(sequence[i:k]) in current_sequence\n",
        "        lambdas += (k - i)\n",
        "    if lambdas==0:\n",
        "        lambdas=1\n",
        "    return lambdas\n",
        "\n",
        "\n",
        "def real_entropy(lambdas, n):\n",
        "    \"\"\"\n",
        "    Estimate the entropy rate of the symbols encoded in the input sequence.\n",
        "\n",
        "    Equation:\n",
        "        S_{real} = \\left( \\frac{1}{n} \\sum \\Lambda_{i} \\right)^{-1}\\log_{2}(n)\n",
        "\n",
        "    Args:\n",
        "        sequence: the input sequence of symbols.\n",
        "    Returns:\n",
        "        A float representing the entropy rate of the input sequence.\n",
        "    Reference:\n",
        "        Kontoyiannis, I., Algoet, P. H., Suhov, Y. M., & Wyner, A. J. (1998).\n",
        "        Nonparametric entropy estimation for stationary processes and random\n",
        "        fields, with applications to English text. IEEE Transactions on Information\n",
        "        Theory, 44(3), 1319-1327.\n",
        "    \"\"\"\n",
        "    return (1.0 * n / lambdas) * np.log(n)\n",
        "\n",
        "def compute_f(p,S,N):\n",
        "    if p<=0 or p>=1 :\n",
        "        print(p)\n",
        "    h = -p * np.log2(p) - (1 - p) * np.log2(1 - p)\n",
        "    pi_max = h + (1 - p) * np.log2(N - 1) - S\n",
        "    return pi_max\n",
        "\n",
        "def getapproximation(p,S,N) :\n",
        "    f= compute_f(p,S,N)\n",
        "    d1 = np.log2(1-p) - np.log2(p) - np.log2(N-1)\n",
        "    d2 = 1 / ((p-1)*p)\n",
        "    return f/(d1-f*d2/(2*d1))\n",
        "\n",
        "def max_predictability(S, N):\n",
        "    \"\"\"\n",
        "    Estimate the maximum predictability of a sequence with\n",
        "    entropy S and alphabet size N.\n",
        "    Equation:\n",
        "    $S = - H(\\Pi) + (1 - \\Pi)\\log(N - 1),$\n",
        "        where $H(\\Pi)$ is given by\n",
        "    $H(\\Pi) = \\Pi \\log_2(\\Pi) + (1 - \\Pi) \\log_2(1 - \\Pi)$\n",
        "    Args:\n",
        "        S: the entropy of the input sequence of symbols.\n",
        "        N: the size of the alphabet (number of unique symbols)\n",
        "    Returns:\n",
        "        the maximum predictability of the sequence.\n",
        "    Reference:\n",
        "        Limits of Predictability in Human Mobility. Chaoming Song, Zehui Qu,\n",
        "        Nicholas Blumm1, Albert-László Barabási. Vol. 327, Issue 5968, pp. 1018-1021.\n",
        "        DOI: 10.1126/science.1177170\n",
        "    \"\"\"\n",
        "    if S>np.log2(N) :\n",
        "        return 0\n",
        "    if S<=0.01 :\n",
        "        return 0.999\n",
        "    p = (N+1)/(2*N)\n",
        "    while(abs(compute_f(p,S,N))>0.0000001):\n",
        "        p = p - 0.8*getapproximation(p,S,N)\n",
        "    return p\n",
        "\n",
        "\n",
        "def regularity(sequence):\n",
        "    \"\"\"\n",
        "    Compute the regularity of a sequence.\n",
        "    The regularity basically measures what percentage of a user's\n",
        "    visits are to a previously visited place.\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequence : list\n",
        "        A list of symbols.\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        100 minus the percentage of the symbols in the sequence that are unique.\n",
        "    \"\"\"\n",
        "    if len(set(sequence)) <= 1:\n",
        "        return 100.0\n",
        "\n",
        "    if len(set(sequence)) == len(sequence):\n",
        "        return .0\n",
        "\n",
        "    return round(100.0 - len(set(sequence)) * 100 / len(sequence), 2)\n",
        "\n",
        "\n",
        "def stationarity(sequence):\n",
        "    \"\"\"\n",
        "    Compute the stationarity of a sequence.\n",
        "    A stationary transition is one whose source and destination symbols\n",
        "    are the same. The stationarity measures the percentage of transitions\n",
        "    to the same location.\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequence : list\n",
        "        A list of symbols.\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Percentage of the sequence that is stationary.\n",
        "    \"\"\"\n",
        "    if len(sequence) <= 1:\n",
        "        return 100.0\n",
        "\n",
        "    if len(sequence) == len(set(sequence)):\n",
        "        return .0\n",
        "\n",
        "    stationary_transitions = 0\n",
        "    for i in range(1, len(sequence)):\n",
        "        if sequence[i - 1] == sequence[i]:\n",
        "            stationary_transitions += 1\n",
        "    return round(stationary_transitions * 100 / (len(sequence) - 1), 2)\n",
        "\n",
        "\n",
        "def diversity(locations, user_home):\n",
        "    \"\"\"\n",
        "    Compute the of trajectories of a user's mobility trace.\n",
        "    The diversity of trajectories is the ratio of unique home-home\n",
        "    trajectories and their sizes compared to the total length of\n",
        "    the trace.\n",
        "    Parameters\n",
        "    ----------\n",
        "    locations : list\n",
        "        A list of locations that a user visited.\n",
        "    user_home : str\n",
        "        A string representing the ID of the location of the user's home.\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The percentage of the overall trajectories that is accounted for\n",
        "        by the unique trajectories.\n",
        "    \"\"\"\n",
        "    if not locations:\n",
        "        return .0\n",
        "\n",
        "    # We assume that the user's trajectory starts and ends at their home location.\n",
        "    if not locations[0].startswith(user_home):\n",
        "        locations = [user_home] + locations\n",
        "    if not locations[-1].startswith(user_home):\n",
        "        locations.append(user_home)\n",
        "\n",
        "    # Split home-to-home trajectories into groups.\n",
        "    trajectories = re.split('(' + str(user_home) + ')', ''.join(str(loc) for loc in locations))\n",
        "\n",
        "    # Counts home-to-home trajectories.\n",
        "    trajectories = [traj for traj in trajectories if traj != '' and traj != user_home]\n",
        "\n",
        "    if len(set(trajectories)) <= 1:\n",
        "        return .0\n",
        "\n",
        "    if len(set(trajectories)) == len(trajectories):\n",
        "        return 100.0\n",
        "\n",
        "    # Compute the diversity of trajectories: number of unique trajectories\n",
        "    # times average size of unique trajectories as a percentage of the\n",
        "    # total number of trajectories.\n",
        "    if trajectories:\n",
        "        unique_trajectories = len(set(trajectories))\n",
        "        mean_unique_trajectory_size = np.mean([max(1, len(traj) // len(str(user_home))) for traj in set(trajectories)])\n",
        "        return (unique_trajectories * mean_unique_trajectory_size) * 100 / len(locations)\n",
        "\n",
        "    return .0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    b= [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "    a= [str(num) for num in b]\n",
        "    lam = lambdas_naive(a)\n",
        "    print(lam)\n",
        "    print(real_entropy(lam,len(a)),unc_entropy(a))\n",
        "    print(max_predictability(real_entropy(lam,len(a)),len(np.unique(a))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi8-vN7Ooz2J",
        "outputId": "04f91321-06d0-4f15-c398-dd741bed45f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "2.70805020110221 3.906890595608518\n",
            "0.5495199405347293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import entropyCompute as eC\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "'''\n",
        "consider both weekday hours and weekend hours \n",
        "'''\n",
        "def hour(times):\n",
        "    times/=1000\n",
        "    timeStamp = times\n",
        "    timeArray = time.localtime(timeStamp)\n",
        "    t=0\n",
        "    if int(timeArray[6])>=5:\n",
        "        t=1\n",
        "    hour =  t* 24 + int(timeArray[3])\n",
        "    return hour\n",
        "\n",
        "'''\n",
        "only get location trajectories without time \n",
        "'''\n",
        "def no_time(seq):\n",
        "    ans = []\n",
        "    for item in seq:\n",
        "        temp = item.split('@')\n",
        "        ans.append(temp[0])\n",
        "    return ans\n",
        "\n",
        "'''\n",
        "normalize the dictionary\n",
        "'''\n",
        "def normalize(x):\n",
        "    sum = np.sum(list(x.values()))\n",
        "    for key in x.keys():\n",
        "        x[key]/=sum\n",
        "    return x\n",
        "\n",
        "'''\n",
        "compute context-transition entropy\n",
        "data format: userid,locatonid@timestamp,locatonid@timestamp,...\n",
        "'''\n",
        "def transShannon(filename,k):\n",
        "    # k means that one transition contains k locations and (k-1)-order transitions\n",
        "    filein = filename + '.txt'\n",
        "    f_transition_entropy = filename+'_transition_'+str(k)+'_entropy.txt'\n",
        "    f_transition_predictability = filename + '_transition_'+str(k)+'_Predictability.txt'\n",
        "    f_context_transition_entropy = filename + '_transition_' + str(k) + '_time_entropy.txt'\n",
        "    f_context_transition_predictability = filename + '_transition_' + str(k) + '_time_Predictability.txt'\n",
        "    cnt_loc={}\n",
        "    cnt_loc_time={}\n",
        "    cnt_time = {}\n",
        "\n",
        "    with open(filein,'r') as fin , \\\n",
        "        open(f_transition_entropy,'w')as fout_transition_entropy ,\\\n",
        "        open(f_context_transition_entropy,'w')as fout_context_transition_entropy,\\\n",
        "        open(f_transition_predictability,'w')as fout_transition_predictability,\\\n",
        "        open(f_context_transition_predictability,'w')as fout_context_transition_predictability:\n",
        "\n",
        "        for line in fin :\n",
        "            temp = line.split(',')\n",
        "            user = temp[0].strip()\n",
        "            seq_time = temp[1:]\n",
        "            seq = no_time(seq_time)\n",
        "            cnt_loc.clear()\n",
        "            cnt_time.clear()\n",
        "            cnt_loc_time.clear()\n",
        "\n",
        "            #count frequency\n",
        "            for i in range(len(seq)-k+1):\n",
        "                trans = seq[i:i+k]\n",
        "                trans = '&'.join(trans)\n",
        "                if trans in cnt_loc.keys():\n",
        "                    cnt_loc[trans]+=1\n",
        "                else:\n",
        "                    cnt_loc[trans]=1\n",
        "\n",
        "                time = str(hour(int(seq_time[i].split('@')[1])))\n",
        "                if time in cnt_time.keys():\n",
        "                    cnt_time[time]+=1\n",
        "                else:\n",
        "                    cnt_time[time] = 1\n",
        "\n",
        "                trans_time = trans+'$'+time\n",
        "                if trans_time in cnt_loc_time.keys():\n",
        "                    cnt_loc_time[trans_time]+=1\n",
        "                else:\n",
        "                    cnt_loc_time[trans_time]=1\n",
        "\n",
        "            #transition Shannon entropy without time\n",
        "            count = list(cnt_loc.values())\n",
        "            probabilities = count / np.sum(count)\n",
        "            unc_entropy = -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "            fout_transition_entropy.write(user+','+str(unc_entropy)+'\\n')\n",
        "            fout_transition_predictability.write(user + ',' +str(eC.max_predictability(unc_entropy,len(cnt_loc.keys())))+'\\n')\n",
        "\n",
        "            #context transition entropy\n",
        "            cnt_time_prob = normalize(cnt_time)\n",
        "            cnt_loc_time_prob = normalize(cnt_loc_time)\n",
        "            cnt_loc_prob = normalize(cnt_loc)\n",
        "            MI = 0\n",
        "            for transTime in cnt_loc_time.keys():\n",
        "                loc,time = transTime.split('$')\n",
        "                MI +=cnt_loc_time_prob[transTime]*np.log2(cnt_loc_time_prob[transTime]/(cnt_loc_prob[loc]*cnt_time_prob[time]))\n",
        "            unc_entropy_time = unc_entropy-MI\n",
        "\n",
        "            fout_context_transition_entropy.write(user + ',' + str(unc_entropy_time) + '\\n')\n",
        "            fout_context_transition_predictability.write(user + ',' + str(eC.max_predictability(unc_entropy_time,len(cnt_loc.keys()))) + '\\n')\n",
        "\n",
        "'''\n",
        "get parameters from scripts\n",
        "'''\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser(description='calculate context transition predictability')\n",
        "    parser.add_argument('--dataset_name',type=str,\n",
        "                        help='dataset name(dont add suffix)')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = get_args()\n",
        "    for i in range(2,7):\n",
        "        transShannon('/content/dataset_TSMC2014_NYC' + args.dataset_name,i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "5nSUq1mhosd0",
        "outputId": "83a44906-0c8b-4a4c-e22b-aab22c6899a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-205444bf3d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mentropyCompute\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0meC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'entropyCompute'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}